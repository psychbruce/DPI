[{"path":"https://psychbruce.github.io/DPI/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Han Wu Shuang Bao. Author, maintainer.","code":""},{"path":"https://psychbruce.github.io/DPI/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Bao H (2026). DPI: Directed Prediction Index Causal Direction Inference Observational Data. R package version 2026.02, https://psychbruce.github.io/DPI/.","code":"@Manual{,   title = {DPI: The Directed Prediction Index for Causal Direction Inference from Observational Data},   author = {Han Wu Shuang Bao},   year = {2026},   note = {R package version 2026.02},   url = {https://psychbruce.github.io/DPI/}, }"},{"path":"https://psychbruce.github.io/DPI/index.html","id":"dpi-","dir":"","previous_headings":"","what":"The Directed Prediction Index for Causal Direction Inference from Observational Data","title":"The Directed Prediction Index for Causal Direction Inference from Observational Data","text":"ðŸ›¸ Directed Prediction Index (DPI). Directed Prediction Index (DPI) causal discovery method observational data designed quantify relative endogeneity outcome (Y) versus predictor (X) variables regression models. âš ï¸ Please use version â‰¥ 2025.11 correct functionality (see Changelog).","code":""},{"path":"https://psychbruce.github.io/DPI/index.html","id":"author","dir":"","previous_headings":"","what":"Author","title":"The Directed Prediction Index for Causal Direction Inference from Observational Data","text":"Bruce H. W. S. Bao åŒ…å¯’å´éœœ ðŸ“¬ baohws@foxmail.com ðŸ“‹ psychbruce.github.io","code":""},{"path":"https://psychbruce.github.io/DPI/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"The Directed Prediction Index for Causal Direction Inference from Observational Data","text":"Bao, H. W. S. (2025). DPI: Directed Prediction Index causal direction inference observational data. https://doi.org/10.32614/CRAN.package.DPI Bao, H. W. S. (preparation). Directed Prediction Index (DPI): Causal direction inference relative endogeneity multivariate observational data. (Manuscript preparation)","code":""},{"path":"https://psychbruce.github.io/DPI/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"The Directed Prediction Index for Causal Direction Inference from Observational Data","text":"","code":"## Method 1: Install from CRAN install.packages(\"DPI\")  ## Method 2: Install from GitHub install.packages(\"devtools\") devtools::install_github(\"psychbruce/DPI\", force=TRUE)"},{"path":"https://psychbruce.github.io/DPI/index.html","id":"algorithm-details","dir":"","previous_headings":"","what":"Algorithm Details","title":"The Directed Prediction Index for Causal Direction Inference from Observational Data","text":"Define DPIâˆˆ(âˆ’1,1)\\text{DPI} \\(-1, 1) RelativeEndogeneityâˆˆ(âˆ’1,1)\\text{RelativeEndogeneity} \\(-1, 1) restricted NormalizedPenaltyâˆˆ(0,1)\\text{NormalizedPenalty} \\(0, 1) Xâ†’YX \\rightarrow Y relationship: DPIXâ†’Y=RelativeEndogeneityXâ†’Yâ‹…NormalizedPenaltyXâ†’Y=Delta(R2)â‹…Sigmoid(pÎ±)=(RYâˆ¼X+Covs2âˆ’RXâˆ¼Y+Covs2)â‹…(1âˆ’tanhpXY|Covs2Î±)âˆˆ(âˆ’1,1) \\begin{aligned} \\text{DPI}_{X \\rightarrow Y} & = \\text{RelativeEndogeneity}_{X \\rightarrow Y} \\cdot \\text{NormalizedPenalty}_{X \\rightarrow Y} \\\\ & = \\text{Delta}(R^2) \\cdot \\text{Sigmoid}(\\frac{p}{\\alpha}) \\\\ & = \\left( R_{Y \\sim X + Covs}^2 - R_{X \\sim Y + Covs}^2 \\right) \\cdot \\left( 1 - \\tanh \\frac{p_{XY|Covs}}{2\\alpha} \\right) \\\\ & \\(-1, 1) \\end{aligned} econometrics broader social sciences, exogenous variable assumed directed (causal quasi-causal) influence endogenous variable (ExoVarâ†’EndoVarExoVar \\rightarrow EndoVar). quantifying relative endogeneity outcome versus predictor variables multiple linear regression models, DPI can suggest plausible (admissible) causal (DPIXâ†’Y>0\\text{DPI}_{X \\rightarrow Y} > 0 necessary insufficient condition Xâ†’YX \\rightarrow Y) controlling possible confounders simulated random covariates.","code":""},{"path":"https://psychbruce.github.io/DPI/index.html","id":"conceptualization-and-computation","dir":"","previous_headings":"Algorithm Details","what":"Conceptualization and Computation","title":"The Directed Prediction Index for Causal Direction Inference from Observational Data","text":"steps compiled DPI() DPI_curve(). See help pages usage illustrative examples. conceptual rationales mathematical explanations.","code":""},{"path":"https://psychbruce.github.io/DPI/index.html","id":"step-1-relative-endogeneity-for-plausible-causal-direction","dir":"","previous_headings":"Algorithm Details > Conceptualization and Computation","what":"Step 1: Relative Endogeneity for Plausible Causal Direction","title":"The Directed Prediction Index for Causal Direction Inference from Observational Data","text":"Define DirectionXâ†’Y\\text{Direction}_{X \\rightarrow Y} relative endogeneity YY vs.Â XX given variable set involving possible confounders CovsCovs: DirectionXâ†’Y=Endogeneity(Y)âˆ’Endogeneity(X)=RYâˆ¼X+Covs2âˆ’RXâˆ¼Y+Covs2=Delta(R2)âˆˆ(âˆ’1,1) \\begin{aligned} \\text{Direction}_{X \\rightarrow Y} & = \\text{Endogeneity}(Y) - \\text{Endogeneity}(X) \\\\ & = R_{Y \\sim X + Covs}^2 - R_{X \\sim Y + Covs}^2 \\\\ & = \\text{Delta}(R^2) \\\\ & \\(-1, 1) \\end{aligned} Delta(R2)\\text{Delta}(R^2)endogeneity score aims test whether YY (outcome), compared XX (predictor), can strongly predicted mm observable control variables (included given sample) kk unobservable random covariates (randomly generated simulation samples, specified k.cov DPI() function). higher R2R^2 indicates higher endogeneity set variables. ideal property, Delta(R2)\\text{Delta}(R^2) can also ensure resulting Directed Acyclic Graph (DAG) structure directed acyclic, since direction (edge) constrained go lower-RÂ² variable (node) higher-RÂ² variable (node) within specific set variables. Therefore, impossible observe cyclic relationship DPI framework.","code":""},{"path":"https://psychbruce.github.io/DPI/index.html","id":"step-2-normalized-penalty-for-insignificant-partial-correlation","dir":"","previous_headings":"Algorithm Details > Conceptualization and Computation","what":"Step 2: Normalized Penalty for Insignificant Partial Correlation","title":"The Directed Prediction Index for Causal Direction Inference from Observational Data","text":"Define Sigmoid(pÎ±)\\text{Sigmoid}(\\frac{p}{\\alpha}) normalized penalty insignificant partial relationship XX YY controlling confounders CovsCovs: Sigmoid(pÎ±)=2[1âˆ’sigmoid(pXY|CovsÎ±)]=1âˆ’tanhpXY|Covs2Î±âˆˆ(0,1) \\begin{aligned} \\text{Sigmoid}(\\frac{p}{\\alpha}) & = 2 \\left[ 1 - \\text{sigmoid}(\\frac{p_{XY|Covs}}{\\alpha}) \\right] \\\\ & = 1 - \\tanh \\frac{p_{XY|Covs}}{2\\alpha} \\\\ & \\(0, 1) \\end{aligned} Sigmoid(pÎ±)\\text{Sigmoid}(\\frac{p}{\\alpha})penalty score aims penalize insignificant (p>Î±p > \\alpha) partial relationship XX YY. Partial correlation rpartialr_{partial} always equivalent tt test pp value partial regression coefficient Î²partial\\beta_{partial} YY XX. higher Sigmoid(pÎ±)\\text{Sigmoid}(\\frac{p}{\\alpha}) indicates likely (less spurious) partial relationship controlling possible confounders. careful suggest strength effect size relationships. used mainly penalizing insignificant partial relationships. control false positive rates, users can set lower Î±\\alpha level (see alpha DPI() related functions) /use Bonferroni correction multiple pairwise tests (see bonf DPI() related functions). Notes transformation among tanh(x)\\tanh(x), sigmoid(x)\\text{sigmoid}(x), Sigmoid(pÎ±)\\text{Sigmoid}(\\frac{p}{\\alpha}): tanh(x)=exâˆ’eâˆ’xex+eâˆ’x=1âˆ’21+e2x=21+eâˆ’2xâˆ’1=2â‹…sigmoid(2x)âˆ’1,âˆˆ(âˆ’1,1)sigmoid(x)=11+eâˆ’x=12[tanh(x2)+1],âˆˆ(0,1)Sigmoid(pÎ±)=2[1âˆ’sigmoid(pÎ±)]=1âˆ’tanhp2Î±.âˆˆ(0,1) \\begin{aligned} \\tanh(x) & = \\frac{e^x - e^{-x}}{e^x + e^{-x}} \\\\ & = 1 - \\frac{2}{1 + e^{2x}} \\\\ & = \\frac{2}{1 + e^{-2x}} - 1 \\\\ & = 2 \\cdot \\text{sigmoid}(2x) - 1, & \\(-1, 1) \\\\ \\text{sigmoid}(x) & = \\frac{1}{1 + e^{-x}} \\\\ & = \\frac{1}{2} \\left[ \\tanh(\\frac{x}{2}) + 1 \\right], & \\(0, 1) \\\\ \\text{Sigmoid}(\\frac{p}{\\alpha}) & = 2 \\left[ 1 - \\text{sigmoid}(\\frac{p}{\\alpha}) \\right] \\\\ & = 1 - \\tanh \\frac{p}{2\\alpha}. & \\(0, 1) \\end{aligned} Wagenmakers (2022) also proposed simple useful algorithm compute approximate (pseudo) Bayes Factors p values sample sizes (see transformation rules ). PseudoBF10(p,n)={13pnif0<pâ‰¤0.10143p2/3nif0.10<pâ‰¤0.501p1/4nif0.50<pâ‰¤1 \\text{PseudoBF}_{10}(p, n) = \\left\\{ \\begin{aligned} & \\frac{1}{3 p \\sqrt n} && \\text{} && 0 < p \\le 0.10 \\\\ & \\frac{1}{\\tfrac{4}{3} p^{2/3} \\sqrt n} && \\text{} && 0.10 < p \\le 0.50 \\\\ & \\frac{1}{p^{1/4} \\sqrt{n}} && \\text{} && 0.50 < p \\le 1 \\end{aligned} \\right. show normalized penalty scores Sigmoid(pÎ±)\\text{Sigmoid}(\\frac{p}{\\alpha}) normalized log pseudo Bayes Factors sigmoid(log(PseudoBF10))\\text{sigmoid}(\\log(\\text{PseudoBF}_{10})) comparable effects penalizing insignificant p values. However, Sigmoid(pÎ±)\\text{Sigmoid}(\\frac{p}{\\alpha}) indeed makes stronger penalties p values p>Î±p > \\alpha restricting penalty scores closer 0, also makes straightforward specification conservative Î± level Bonferroni correction p values multiple pairwise DPI tests.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/DPI/index.html","id":"step-3-data-simulation","dir":"","previous_headings":"Algorithm Details > Conceptualization and Computation","what":"Step 3: Data Simulation","title":"The Directed Prediction Index for Causal Direction Inference from Observational Data","text":"(1) Main analysis using DPI(): Simulate n.sim random samples, k.cov (unobservable) random covariate(s) simulated sample, test statistical significance DPI. (2) Robustness check using DPI_curve(): Run series DPI simulation analyses respectively 1~k.covs (usually 1~10) random covariates, producing curve DPIs (estimates 95% CI; usually getting closer 0 k.covs increases) can indicate sensitivity identifying directed prediction (.e., many random covariates can DPIs survive remain significant?). (3) Causal discovery using DPI_dag(): Directed acyclic graphs (DAGs) via DPI exploratory analysis significant partial correlations.","code":""},{"path":"https://psychbruce.github.io/DPI/index.html","id":"other-functions","dir":"","previous_headings":"","what":"Other Functions","title":"The Directed Prediction Index for Causal Direction Inference from Observational Data","text":"package also includes functions helpful exploring variable relationships performing simulation studies. Network analysis functions cor_net(): Correlation partial correlation networks. BNs_dag(): Directed acyclic graphs (DAGs) via Bayesian networks (BNs). Data simulation functions sim_data(): Simulate data multivariate normal distribution. sim_data_exp(): Simulate experiment-like data independent binary Xs. Miscellaneous functions cor_matrix(): Produce symmetric correlation matrix values. p_to_bf(): Convert p values pseudo Bayes Factors (PseudoBF10\\text{PseudoBF}_{10}).","code":""},{"path":"https://psychbruce.github.io/DPI/reference/BNs_dag.html","id":null,"dir":"Reference","previous_headings":"","what":"Directed acyclic graphs (DAGs) via Bayesian networks (BNs). â€” BNs_dag","title":"Directed acyclic graphs (DAGs) via Bayesian networks (BNs). â€” BNs_dag","text":"Directed acyclic graphs (DAGs) via Bayesian networks (BNs). uses bnlearn::boot.strength() estimate strength edge empirical frequency set networks learned bootstrap samples. computes (1) probability edge (modulo direction) (2) probabilities edge's directions conditional edge present graph (either direction). Stability thresholds usually set 0.85 strength (.e., edge appearing 85% BNs bootstrap samples) 0.50 direction (.e., direction appearing 50% BNs bootstrap samples) (Briganti et al., 2023). Finally, chosen algorithm, returns stable Bayesian network final DAG.","code":""},{"path":"https://psychbruce.github.io/DPI/reference/BNs_dag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Directed acyclic graphs (DAGs) via Bayesian networks (BNs). â€” BNs_dag","text":"","code":"BNs_dag(   data,   algorithm = c(\"pc.stable\", \"hc\", \"rsmax2\"),   algorithm.args = list(),   n.boot = 1000,   seed = NULL,   strength = 0.85,   direction = 0.5,   node.text.size = 1.2,   edge.width.max = 1.5,   edge.label.mrg = 0.01,   file = NULL,   width = 6,   height = 4,   dpi = 500,   verbose = TRUE,   ... )"},{"path":"https://psychbruce.github.io/DPI/reference/BNs_dag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Directed acyclic graphs (DAGs) via Bayesian networks (BNs). â€” BNs_dag","text":"data Data. algorithm Structure learning algorithms building Bayesian networks (BNs). function name(s) bnlearn package. Better perform BNs three classes algorithms check robustness results (Briganti et al., 2023). Defaults common algorithms: \"pc.stable\" (PC), \"hc\" (HC), \"rsmax2\" (RS), three classes, respectively. (1) Constraint-based Algorithms PC: \"pc.stable\" (first practical constraint-based causal structure learning algorithm Peter & Clark) Others: \"gs\", \"iamb\", \"fast.iamb\", \"inter.iamb\", \"iamb.fdr\" (2) Score-based Algorithms Hill-Climbing: \"hc\" (hill-climbing greedy search algorithm, exploring DAGs single-edge additions, removals, reversals, random restarts avoid local optima) Others: \"tabu\" (3) Hybrid Algorithms (combination constraint-based score-based algorithms) Restricted Maximization: \"rsmax2\" (general 2-phase restricted maximization algorithm, first restricting search space finding optimal [maximizing score ] network structure restricted space) Others: \"mmhc\", \"h2pc\" algorithm.args optional list extra arguments passed algorithm. n.boot Number bootstrap samples (learning \"stable\" network structure). Defaults 1000. seed Random seed replicable results. Defaults NULL. strength Stability threshold edge strength: minimum proportion (probability) BNs (among n.boot bootstrap samples) edge appears. Defaults 0.85 (85%). Two reverse directions share edge strength. Empirical frequency (?~100%) mapped onto edge width/thickness final integrated DAG, wider (thicker) edges showing stronger links, though usually look similar since default range limited 0.85~1. direction Stability threshold edge direction: minimum proportion (probability) BNs (among n.boot bootstrap samples) direction edge appears. Defaults 0.50 (50%). proportions two reverse directions add 100%. Empirical frequency (?~100%) mapped onto edge greyscale/transparency final integrated DAG, value shown edge text label. node.text.size Scalar font size node (variable) labels. Defaults 1.2. edge.width.max Maximum value edge strength scale edge widths. Defaults NULL (undirected correlation networks) 1.5 (directed acyclic networks better display arrows). edge.label.mrg Margin background box around edge label. Defaults 0.01. file File name saved plot (\".png\" \".pdf\"). width, height Width height (inches) saved plot. Defaults 6 4. dpi Dots per inch (figure resolution). Defaults 500. verbose Print information BN algorithm number bootstrap samples running analysis. Defaults TRUE. ... Arguments passed qgraph().","code":""},{"path":"https://psychbruce.github.io/DPI/reference/BNs_dag.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Directed acyclic graphs (DAGs) via Bayesian networks (BNs). â€” BNs_dag","text":"Return list (class bns.dag) Bayesian network results qgraph object.","code":""},{"path":"https://psychbruce.github.io/DPI/reference/BNs_dag.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Directed acyclic graphs (DAGs) via Bayesian networks (BNs). â€” BNs_dag","text":"Briganti, G., Scutari, M., & McNally, R. J. (2023). tutorial Bayesian networks psychopathology researchers. Psychological Methods, 28(4), 947â€“961. doi:10.1037/met0000479 Burger, J., Isvoranu, .-M., Lunansky, G., Haslbeck, J. M. B., Epskamp, S., Hoekstra, R. H. ., Fried, E. ., Borsboom, D., & Blanken, T. F. (2023). Reporting standards psychological network analyses cross-sectional data. Psychological Methods, 28(4), 806â€“824. doi:10.1037/met0000471 Scutari, M., & Denis, J.-B. (2021). Bayesian networks: examples R (2nd ed.). Chapman Hall/CRC. doi:10.1201/9780429347436 https://www.bnlearn.com/","code":""},{"path":[]},{"path":"https://psychbruce.github.io/DPI/reference/BNs_dag.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Directed acyclic graphs (DAGs) via Bayesian networks (BNs). â€” BNs_dag","text":"","code":"bn = BNs_dag(airquality, seed=1) #> Warning: Missing values (NA) found in data! #>  #> BNs results would be affected by missing values! #>  #> You may use `na.omit()` to delete missing values listwise. #> Running BN algorithm \"pc.stable\" with 1000 bootstrap samples... #> Running BN algorithm \"hc\" with 1000 bootstrap samples... #> Running BN algorithm \"rsmax2\" with 1000 bootstrap samples... bn #> Displaying DAG with BN algorithm \"pc.stable\"  #> Displaying DAG with BN algorithm \"hc\"  #> Displaying DAG with BN algorithm \"rsmax2\"  # bn$pc.stable # bn$hc # bn$rsmax2  ## All DAG objects can be directly plotted ## or saved with print(..., file=\"xxx.png\") # bn$pc.stable$DAG.edge # bn$pc.stable$DAG.strength # bn$pc.stable$DAG.direction # bn$pc.stable$DAG # ...  if (FALSE) { # \\dontrun{  print(bn, file=\"airquality.png\") # will save three plots with auto-modified file names: - \"airquality_BNs.DAG.01_pc.stable.png\" - \"airquality_BNs.DAG.02_hc.png\" - \"airquality_BNs.DAG.03_rsmax2.png\"  # arrange multiple plots using aplot::plot_list() # install.packages(\"aplot\") c1 = cor_net(airquality, \"cor\") c2 = cor_net(airquality, \"pcor\") bn = BNs_dag(airquality, seed=1) mytheme = theme(plot.title=element_text(hjust=0.5)) p = aplot::plot_list(   plot(c1),   plot(c2),   plot(bn$pc.stable$DAG) + mytheme,   plot(bn$hc$DAG) + mytheme,   plot(bn$rsmax2$DAG) + mytheme,   design=\"111222           334455\",   tag_levels=\"A\" )  # return a patchwork object ggsave(p, filename=\"p.png\", width=12, height=8, dpi=500) ggsave(p, filename=\"p.pdf\", width=12, height=8) } # }"},{"path":"https://psychbruce.github.io/DPI/reference/DPI-package.html","id":null,"dir":"Reference","previous_headings":"","what":"DPI: The Directed Prediction Index for Causal Direction Inference from Observational Data â€” DPI-package","title":"DPI: The Directed Prediction Index for Causal Direction Inference from Observational Data â€” DPI-package","text":"Directed Prediction Index ('DPI') causal discovery method observational data designed quantify relative endogeneity outcome (Y) versus predictor (X) variables regression models. comparing coefficients determination (R-squared) Y--outcome X--outcome models controlling sufficient confounders simulating k random covariates, can quantify relative endogeneity, providing necessary insufficient condition causal direction less endogenous variable (X) endogenous variable (Y). Methodological details provided https://psychbruce.github.io/DPI/. package also includes functions data simulation network analysis (correlation, partial correlation, Bayesian Networks).","code":""},{"path":[]},{"path":"https://psychbruce.github.io/DPI/reference/DPI-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"DPI: The Directed Prediction Index for Causal Direction Inference from Observational Data â€” DPI-package","text":"Maintainer: Han Wu Shuang Bao baohws@foxmail.com (ORCID)","code":""},{"path":"https://psychbruce.github.io/DPI/reference/DPI.html","id":null,"dir":"Reference","previous_headings":"","what":"The Directed Prediction Index (DPI). â€” DPI","title":"The Directed Prediction Index (DPI). â€” DPI","text":"Directed Prediction Index (DPI) causal discovery method observational data designed quantify relative endogeneity outcome (Y) vs. predictor (X) variables regression models. comparing coefficients determination (R-squared) Y--outcome X--outcome models controlling sufficient confounders simulating k random covariates, can quantify relative endogeneity, providing necessary insufficient condition causal direction exogenous variable (X) endogenous variable (Y). Methodological details provided https://psychbruce.github.io/DPI/.","code":""},{"path":"https://psychbruce.github.io/DPI/reference/DPI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Directed Prediction Index (DPI). â€” DPI","text":"","code":"DPI(   model,   x,   y,   data = NULL,   k.cov = 1,   n.sim = 1000,   alpha = 0.05,   bonf = FALSE,   pseudoBF = FALSE,   seed = NULL,   progress,   file = NULL,   width = 6,   height = 4,   dpi = 500 )"},{"path":"https://psychbruce.github.io/DPI/reference/DPI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Directed Prediction Index (DPI). â€” DPI","text":"model Model object (lm). x Independent (predictor) variable. y Dependent (outcome) variable. data [Optional] Defaults NULL. data specified, model ignored linear model lm({y} ~ {x} + .) fitted inside. helpful exploring variables dataset. k.cov Number random covariates (simulating potential omitted variables) added simulation sample. Defaults 1. Please also test different k.cov values robustness checks (see DPI_curve()). k.cov > 0, raw data (without bootstrapping) used, k.cov random variables appended, simulation. k.cov = 0 (suggested), bootstrap samples (resampling replacement) used simulation. n.sim Number simulation samples. Defaults 1000. alpha Significance level computing Normalized Penalty score (0~1) based p value partial correlation X Y. Defaults 0.05. bonf Bonferroni correction control false positive rates: alpha divided , p values multiplied , number comparisons. Defaults FALSE: correction, suitable plan test one pair variables. TRUE: Using k * (k - 1) / 2 (pairs variables) k = length(data). user-specified number comparisons. pseudoBF Use normalized pseudo Bayes Factors sigmoid(log(PseudoBF10)) alternatively Normalized Penalty score (0~1). Pseudo Bayes Factors computed p value X-Y partial relationship total sample size, using transformation rules proposed Wagenmakers (2022) doi:10.31234/osf.io/egydq . Defaults FALSE makes less penalties insignificant partial relationships X Y, see Examples DPI() online documentation. seed Random seed replicable results. Defaults NULL. progress Show progress bar. Defaults FALSE (n.sim < 5000). file File name saved plot (\".png\" \".pdf\"). width, height Width height (inches) saved plot. Defaults 6 4. dpi Dots per inch (figure resolution). Defaults 500.","code":""},{"path":"https://psychbruce.github.io/DPI/reference/DPI.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The Directed Prediction Index (DPI). â€” DPI","text":"Return data.frame simulation results: DPI = Relative Endogeneity * Normalized Penalty = (R2.Y - R2.X) * (1 - tanh(p.beta.xy/alpha/2)) pseudoBF=FALSE (default, suggested) conservative estimates = (R2.Y - R2.X) * plogis(log(pseudo.BF.xy)) pseudoBF=TRUE less conservative insignificant X-Y relationship delta.R2 R2.Y - R2.X R2.Y \\(R^2\\) regression model predicting Y using X covariates R2.X \\(R^2\\) regression model predicting X using Y covariates t.beta.xy t value coefficient X predicting Y (always equal t value coefficient Y predicting X) controlling covariates p.beta.xy p value coefficient X predicting Y (always equal p value coefficient Y predicting X) controlling covariates df.beta.xy residual degree freedom (df) t.beta.xy r.partial.xy partial correlation (always t value t.beta.xy) X Y controlling covariates sigmoid.p.xy sigmoid p value 1 - tanh(p.beta.xy/alpha/2) pseudo.BF.xy pseudo Bayes Factors (\\(BF_{10}\\)) computed p value p.beta.xy sample size nobs(model), see p_to_bf()","code":""},{"path":[]},{"path":"https://psychbruce.github.io/DPI/reference/DPI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"The Directed Prediction Index (DPI). â€” DPI","text":"","code":"# input a fitted model model = lm(Ozone ~ ., data=airquality) DPI(model, x=\"Solar.R\", y=\"Ozone\", seed=1)  # DPI > 0 #> Sample size: N.valid = 111 #> Model Y formula: Ozone ~ Solar.R + Wind + Temp + Month + Day #> Model X formula: Solar.R ~ Ozone + Wind + Temp + Month + Day #> Directed prediction: \"Solar.R\" (X) -> \"Ozone\" (Y) #> Partial correlation: r.partial = 0.205, p = 0.0353 *  (PseudoBF10 = 0.897) #> Normalized penalty method: Sigmoid(p/alpha) = 1 - tanh(p.xy/alpha/2) #> Simulation sample setting: k.random.covs = 1, n.sim = 1000, seed = 1 #> False positive rates (FPR) control: Alpha = 0.05 (Bonferroni correction = 1) #>     Estimate  Sim.SE z.value   p.z sig  Conf.Interval log.PseudoBF10 #> DPI    0.297 (0.031)   9.453 3e-21 *** [0.236, 0.359]         43.710  DPI(model, x=\"Wind\", y=\"Ozone\", seed=1)     # DPI > 0 #> Sample size: N.valid = 111 #> Model Y formula: Ozone ~ Wind + Solar.R + Temp + Month + Day #> Model X formula: Wind ~ Ozone + Solar.R + Temp + Month + Day #> Directed prediction: \"Wind\" (X) -> \"Ozone\" (Y) #> Partial correlation: r.partial = -0.449, p = 1e-06 *** (PseudoBF10 = 23117.101) #> Normalized penalty method: Sigmoid(p/alpha) = 1 - tanh(p.xy/alpha/2) #> Simulation sample setting: k.random.covs = 1, n.sim = 1000, seed = 1 #> False positive rates (FPR) control: Alpha = 0.05 (Bonferroni correction = 1) #>     Estimate  Sim.SE z.value    p.z sig  Conf.Interval log.PseudoBF10 #> DPI    0.223 (0.009)  25.296 <1e-99 *** [0.206, 0.240]        319.946  DPI(model, x=\"Solar.R\", y=\"Wind\", seed=1)   # unrelated #> Sample size: N.valid = 111 #> Model Y formula: Wind ~ Solar.R + Ozone + Temp + Month + Day #> Model X formula: Solar.R ~ Wind + Ozone + Temp + Month + Day #> Directed prediction: \"Solar.R\" (X) -> \"Wind\" (Y) #> Partial correlation: r.partial = 0.114, p = 0.2447   (PseudoBF10 = 0.182) #> Normalized penalty method: Sigmoid(p/alpha) = 1 - tanh(p.xy/alpha/2) #> Simulation sample setting: k.random.covs = 1, n.sim = 1000, seed = 1 #> False positive rates (FPR) control: Alpha = 0.05 (Bonferroni correction = 1) #>     Estimate  Sim.SE z.value    p.z sig   Conf.Interval log.PseudoBF10 #> DPI    0.004 (0.005)   0.903 0.3666     [-0.005, 0.014]         -1.974   # or input raw data, test with more random covs DPI(data=airquality, x=\"Solar.R\", y=\"Ozone\",     k.cov=10, seed=1) #> Sample size: N.valid = 111 #> Model Y formula: Ozone ~ Solar.R + Wind + Temp + Month + Day #> Model X formula: Solar.R ~ Ozone + Wind + Temp + Month + Day #> Directed prediction: \"Solar.R\" (X) -> \"Ozone\" (Y) #> Partial correlation: r.partial = 0.204, p = 0.0452 *  (PseudoBF10 = 0.700) #> Normalized penalty method: Sigmoid(p/alpha) = 1 - tanh(p.xy/alpha/2) #> Simulation sample setting: k.random.covs = 10, n.sim = 1000, seed = 1 #> False positive rates (FPR) control: Alpha = 0.05 (Bonferroni correction = 1) #>     Estimate  Sim.SE z.value    p.z sig  Conf.Interval log.PseudoBF10 #> DPI    0.226 (0.096)   2.342 0.0192 *   [0.037, 0.415]          0.501  DPI(data=airquality, x=\"Wind\", y=\"Ozone\",     k.cov=10, seed=1) #> Sample size: N.valid = 111 #> Model Y formula: Ozone ~ Wind + Solar.R + Temp + Month + Day #> Model X formula: Wind ~ Ozone + Solar.R + Temp + Month + Day #> Directed prediction: \"Wind\" (X) -> \"Ozone\" (Y) #> Partial correlation: r.partial = -0.449, p = 4e-06 *** (PseudoBF10 = 8372.103) #> Normalized penalty method: Sigmoid(p/alpha) = 1 - tanh(p.xy/alpha/2) #> Simulation sample setting: k.random.covs = 10, n.sim = 1000, seed = 1 #> False positive rates (FPR) control: Alpha = 0.05 (Bonferroni correction = 1) #>     Estimate  Sim.SE z.value   p.z sig  Conf.Interval log.PseudoBF10 #> DPI    0.203 (0.027)   7.567 4e-14 *** [0.150, 0.255]         27.442  DPI(data=airquality, x=\"Solar.R\", y=\"Wind\",     k.cov=10, seed=1) #> Sample size: N.valid = 111 #> Model Y formula: Wind ~ Solar.R + Ozone + Temp + Month + Day #> Model X formula: Solar.R ~ Wind + Ozone + Temp + Month + Day #> Directed prediction: \"Solar.R\" (X) -> \"Wind\" (Y) #> Partial correlation: r.partial = 0.111, p = 0.2765   (PseudoBF10 = 0.168) #> Normalized penalty method: Sigmoid(p/alpha) = 1 - tanh(p.xy/alpha/2) #> Simulation sample setting: k.random.covs = 10, n.sim = 1000, seed = 1 #> False positive rates (FPR) control: Alpha = 0.05 (Bonferroni correction = 1) #>     Estimate  Sim.SE z.value    p.z sig   Conf.Interval log.PseudoBF10 #> DPI    0.008 (0.017)   0.492 0.6225     [-0.025, 0.041]         -2.236   # or use pseudo Bayes Factors for normalized penalty # (less conservative for insignificant X-Y relationship) DPI(data=airquality, x=\"Solar.R\", y=\"Ozone\", k.cov=10,     pseudoBF=TRUE, seed=1)  # DPI > 0 (true positive) #> Sample size: N.valid = 111 #> Model Y formula: Ozone ~ Solar.R + Wind + Temp + Month + Day #> Model X formula: Solar.R ~ Ozone + Wind + Temp + Month + Day #> Directed prediction: \"Solar.R\" (X) -> \"Ozone\" (Y) #> Partial correlation: r.partial = 0.204, p = 0.0452 *  (PseudoBF10 = 0.700) #> Normalized penalty method: Sigmoid(log(PseudoBF10.xy)) #> Simulation sample setting: k.random.covs = 10, n.sim = 1000, seed = 1 #> False positive rates (FPR) control: Alpha = 0.05 (Bonferroni correction = 1) #>     Estimate  Sim.SE z.value    p.z sig  Conf.Interval log.PseudoBF10 #> DPI    0.178 (0.067)   2.654 0.0080 **  [0.046, 0.309]          1.380  DPI(data=airquality, x=\"Wind\", y=\"Ozone\", k.cov=10,     pseudoBF=TRUE, seed=1)  # DPI > 0 (true positive) #> Sample size: N.valid = 111 #> Model Y formula: Ozone ~ Wind + Solar.R + Temp + Month + Day #> Model X formula: Wind ~ Ozone + Solar.R + Temp + Month + Day #> Directed prediction: \"Wind\" (X) -> \"Ozone\" (Y) #> Partial correlation: r.partial = -0.449, p = 4e-06 *** (PseudoBF10 = 8372.103) #> Normalized penalty method: Sigmoid(log(PseudoBF10.xy)) #> Simulation sample setting: k.random.covs = 10, n.sim = 1000, seed = 1 #> False positive rates (FPR) control: Alpha = 0.05 (Bonferroni correction = 1) #>     Estimate  Sim.SE z.value   p.z sig  Conf.Interval log.PseudoBF10 #> DPI    0.203 (0.027)   7.567 4e-14 *** [0.150, 0.255]         27.443  DPI(data=airquality, x=\"Solar.R\", y=\"Wind\", k.cov=10,     pseudoBF=TRUE, seed=1)  # DPI > 0 (false positive!) #> Sample size: N.valid = 111 #> Model Y formula: Wind ~ Solar.R + Ozone + Temp + Month + Day #> Model X formula: Solar.R ~ Wind + Ozone + Temp + Month + Day #> Directed prediction: \"Solar.R\" (X) -> \"Wind\" (Y) #> Partial correlation: r.partial = 0.111, p = 0.2765   (PseudoBF10 = 0.168) #> Normalized penalty method: Sigmoid(log(PseudoBF10.xy)) #> Simulation sample setting: k.random.covs = 10, n.sim = 1000, seed = 1 #> False positive rates (FPR) control: Alpha = 0.05 (Bonferroni correction = 1) #>     Estimate  Sim.SE z.value    p.z sig  Conf.Interval log.PseudoBF10 #> DPI    0.032 (0.012)   2.767 0.0057 **  [0.009, 0.055]          1.722"},{"path":"https://psychbruce.github.io/DPI/reference/DPI_curve.html","id":null,"dir":"Reference","previous_headings":"","what":"DPI curve analysis across multiple random covariates. â€” DPI_curve","title":"DPI curve analysis across multiple random covariates. â€” DPI_curve","text":"DPI curve analysis across multiple random covariates.","code":""},{"path":"https://psychbruce.github.io/DPI/reference/DPI_curve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DPI curve analysis across multiple random covariates. â€” DPI_curve","text":"","code":"DPI_curve(   model,   x,   y,   data = NULL,   k.covs = 1:10,   n.sim = 1000,   alpha = 0.05,   bonf = FALSE,   pseudoBF = FALSE,   seed = NULL,   progress,   file = NULL,   width = 6,   height = 4,   dpi = 500 )"},{"path":"https://psychbruce.github.io/DPI/reference/DPI_curve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"DPI curve analysis across multiple random covariates. â€” DPI_curve","text":"model Model object (lm). x Independent (predictor) variable. y Dependent (outcome) variable. data [Optional] Defaults NULL. data specified, model ignored linear model lm({y} ~ {x} + .) fitted inside. helpful exploring variables dataset. k.covs integer vector number random covariates (simulating potential omitted variables) added simulation sample. Defaults 1:10 (producing DPI results k.cov=1~10). details, see DPI(). n.sim Number simulation samples. Defaults 1000. alpha Significance level computing Normalized Penalty score (0~1) based p value partial correlation X Y. Defaults 0.05. bonf Bonferroni correction control false positive rates: alpha divided , p values multiplied , number comparisons. Defaults FALSE: correction, suitable plan test one pair variables. TRUE: Using k * (k - 1) / 2 (pairs variables) k = length(data). user-specified number comparisons. pseudoBF Use normalized pseudo Bayes Factors sigmoid(log(PseudoBF10)) alternatively Normalized Penalty score (0~1). Pseudo Bayes Factors computed p value X-Y partial relationship total sample size, using transformation rules proposed Wagenmakers (2022) doi:10.31234/osf.io/egydq . Defaults FALSE makes less penalties insignificant partial relationships X Y, see Examples DPI() online documentation. seed Random seed replicable results. Defaults NULL. progress Show progress bar. Defaults TRUE (length(k.covs) >= 5). file File name saved plot (\".png\" \".pdf\"). width, height Width height (inches) saved plot. Defaults 6 4. dpi Dots per inch (figure resolution). Defaults 500.","code":""},{"path":"https://psychbruce.github.io/DPI/reference/DPI_curve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"DPI curve analysis across multiple random covariates. â€” DPI_curve","text":"Return data.frame DPI curve results.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/DPI/reference/DPI_curve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"DPI curve analysis across multiple random covariates. â€” DPI_curve","text":"","code":"model = lm(Ozone ~ ., data=airquality) DPIs = DPI_curve(model, x=\"Solar.R\", y=\"Ozone\", seed=1) #> â ™ Simulation k.covs: 1/10 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   10% [00:00:3.6] #> â ¹ Simulation k.covs: 2/10 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   20% [00:00:7.6] #> â ¸ Simulation k.covs: 3/10 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   30% [00:00:11.5] #> â ¼ Simulation k.covs: 4/10 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   40% [00:00:15.5] #> â ´ Simulation k.covs: 5/10 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   50% [00:00:19.7] #> â ¦ Simulation k.covs: 6/10 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   60% [00:00:24] #> â § Simulation k.covs: 7/10 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   70% [00:00:28.5] #> â ‡ Simulation k.covs: 8/10 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   80% [00:00:33.2] #> â  Simulation k.covs: 9/10 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   90% [00:00:38.2] #> âœ” 10 * 1000 simulation samples estimated in 43.1s #>  plot(DPIs)  # ggplot object"},{"path":"https://psychbruce.github.io/DPI/reference/DPI_dag.html","id":null,"dir":"Reference","previous_headings":"","what":"Directed acyclic graphs (DAGs) via DPI exploratory analysis (causal discovery) for all significant partial rs. â€” DPI_dag","title":"Directed acyclic graphs (DAGs) via DPI exploratory analysis (causal discovery) for all significant partial rs. â€” DPI_dag","text":"Directed acyclic graphs (DAGs) via DPI exploratory analysis (causal discovery) significant partial rs.","code":""},{"path":"https://psychbruce.github.io/DPI/reference/DPI_dag.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Directed acyclic graphs (DAGs) via DPI exploratory analysis (causal discovery) for all significant partial rs. â€” DPI_dag","text":"","code":"DPI_dag(   data,   k.covs = 1,   n.sim = 1000,   alpha = 0.05,   bonf = FALSE,   pseudoBF = FALSE,   seed = NULL,   node.text.size = 1.2,   progress,   file = NULL,   width = 6,   height = 4,   dpi = 500 )"},{"path":"https://psychbruce.github.io/DPI/reference/DPI_dag.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Directed acyclic graphs (DAGs) via DPI exploratory analysis (causal discovery) for all significant partial rs. â€” DPI_dag","text":"data dataset least 3 variables. k.covs integer vector (e.g., 1:10) number random covariates (simulating potential omitted variables) added simulation sample. Defaults 1. details, see DPI(). n.sim Number simulation samples. Defaults 1000. alpha Significance level computing Normalized Penalty score (0~1) based p value partial correlation X Y. Defaults 0.05. bonf Bonferroni correction control false positive rates: alpha divided , p values multiplied , number comparisons. Defaults FALSE: correction, suitable plan test one pair variables. TRUE: Using k * (k - 1) / 2 (pairs variables) k = length(data). user-specified number comparisons. pseudoBF Use normalized pseudo Bayes Factors sigmoid(log(PseudoBF10)) alternatively Normalized Penalty score (0~1). Pseudo Bayes Factors computed p value X-Y partial relationship total sample size, using transformation rules proposed Wagenmakers (2022) doi:10.31234/osf.io/egydq . Defaults FALSE makes less penalties insignificant partial relationships X Y, see Examples DPI() online documentation. seed Random seed replicable results. Defaults NULL. node.text.size Scalar font size node (variable) labels. Defaults 1.2. progress Show progress bar. Defaults TRUE (length(k.covs) >= 5). file File name saved plot (\".png\" \".pdf\"). width, height Width height (inches) saved plot. Defaults 6 4. dpi Dots per inch (figure resolution). Defaults 500.","code":""},{"path":"https://psychbruce.github.io/DPI/reference/DPI_dag.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Directed acyclic graphs (DAGs) via DPI exploratory analysis (causal discovery) for all significant partial rs. â€” DPI_dag","text":"Return data.frame (class dpi.dag) DPI exploration results.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/DPI/reference/DPI_dag.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Directed acyclic graphs (DAGs) via DPI exploratory analysis (causal discovery) for all significant partial rs. â€” DPI_dag","text":"","code":"# partial correlation networks (undirected) cor_net(airquality, \"pcor\") #> Displaying Partial Correlation Network   # directed acyclic graphs (grey edge = insignificant DPI) dpi.dag = DPI_dag(airquality, k.covs=c(1,3,5), seed=1) #> Sample size: N.valid = 111 #> Normalized penalty method: Sigmoid(p/alpha) = 1 - tanh(p.xy/alpha/2) #> Simulation sample setting: k.covs = 1, 3, and 5, n.sim = 1000, seed = 1 #> False positive rates (FPR) control: Alpha = 0.05 (Bonferroni correction = 1) #>  #> Exploring [1/5]: #> r.partial = 0.560, p = 4e-10 *** (PseudoBF10 = 8.650e+07) #> --------- DPI[\"Temp\"->\"Ozone\"](1) = 0.023, p = 5e-05 *** #> --------- DPI[\"Temp\"->\"Ozone\"](3) = 0.023, p = 0.020 * #> --------- DPI[\"Temp\"->\"Ozone\"](5) = 0.022, p = 0.085 . #>  #> Exploring [2/5]: #> r.partial = 0.438, p = 2e-06 *** (PseudoBF10 = 13070.747) #> --------- DPI[\"Month\"->\"Temp\"](1) = 0.364, p = <1e-99 *** #> --------- DPI[\"Month\"->\"Temp\"](3) = 0.357, p = 8e-87 *** #> --------- DPI[\"Month\"->\"Temp\"](5) = 0.350, p = 1e-52 *** #>  #> Exploring [3/5]: #> r.partial = 0.205, p = 0.034 *  (PseudoBF10 = 0.927) #> --------- DPI[\"Solar.R\"->\"Ozone\"](1) = 0.297, p = 3e-21 *** #> --------- DPI[\"Solar.R\"->\"Ozone\"](3) = 0.281, p = 4e-07 *** #> --------- DPI[\"Solar.R\"->\"Ozone\"](5) = 0.265, p = 2e-04 *** #>  #> Exploring [4/5]: #> r.partial = -0.192, p = 0.047 *  (PseudoBF10 = 0.671) #> --------- DPI[\"Month\"->\"Ozone\"](1) = 0.214, p = 6e-12 *** #> --------- DPI[\"Month\"->\"Ozone\"](3) = 0.204, p = 1e-04 *** #> --------- DPI[\"Month\"->\"Ozone\"](5) = 0.193, p = 0.003 ** #>  #> Exploring [5/5]: #> r.partial = -0.449, p = 1e-06 *** (PseudoBF10 = 25695.789) #> --------- DPI[\"Wind\"->\"Ozone\"](1) = 0.223, p = <1e-99 *** #> --------- DPI[\"Wind\"->\"Ozone\"](3) = 0.219, p = 3e-50 *** #> --------- DPI[\"Wind\"->\"Ozone\"](5) = 0.214, p = 8e-28 *** print(dpi.dag, k=1)  # DAG with DPI(k=1) #> Displaying DAG with DPI algorithm (k.cov = 1)  print(dpi.dag, k=3)  # DAG with DPI(k=3) #> Displaying DAG with DPI algorithm (k.cov = 3)  print(dpi.dag, k=5)  # DAG with DPI(k=5) #> Displaying DAG with DPI algorithm (k.cov = 5)   # set edge labels and edge transparency # (grey edge = insignificant DPI) print(dpi.dag, k=5, show.label=FALSE, faded.dpi=TRUE) #> Displaying DAG with DPI algorithm (k.cov = 5)   # modify ggplot attributes gg = plot(dpi.dag, k=5, show.label=FALSE, faded.dpi=TRUE) gg + labs(title=\"DAG with DPI (k=5)\")   # visualize DPIs of multiple paths ggplot(dpi.dag$DPI, aes(x=k.cov, y=DPI)) +   geom_ribbon(     aes(ymin=Sim.LLCI, ymax=Sim.ULCI, fill=path),         alpha=0.1) +   geom_line(aes(color=path), linewidth=0.7) +   geom_point(aes(color=path)) +   geom_hline(yintercept=0, color=\"red\",              linetype=\"dashed\") +   scale_y_continuous(limits=c(NA, 0.5)) +   labs(color=\"Directed Prediction\",        fill=\"Directed Prediction\") +   theme_classic()"},{"path":"https://psychbruce.github.io/DPI/reference/S3method.dpi.html","id":null,"dir":"Reference","previous_headings":"","what":"[S3 methods] for DPI() and DPI_curve(). â€” S3method.dpi","title":"[S3 methods] for DPI() and DPI_curve(). â€” S3method.dpi","text":"summary(dpi) Summarize DPI results. Return list (class summary.dpi) summarized results raw DPI data.frame. print(summary.dpi) Print DPI summary. plot(dpi) Plot DPI results. Return ggplot object. print(dpi) Print DPI summary plot. plot(dpi.curve) Plot DPI curve analysis results. Return ggplot object.","code":""},{"path":"https://psychbruce.github.io/DPI/reference/S3method.dpi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"[S3 methods] for DPI() and DPI_curve(). â€” S3method.dpi","text":"","code":"# S3 method for class 'dpi' summary(object, ...)  # S3 method for class 'summary.dpi' print(x, digits = 3, ...)  # S3 method for class 'dpi' plot(x, file = NULL, width = 6, height = 4, dpi = 500, ...)  # S3 method for class 'dpi' print(x, digits = 3, ...)  # S3 method for class 'dpi.curve' plot(x, file = NULL, width = 6, height = 4, dpi = 500, ...)"},{"path":"https://psychbruce.github.io/DPI/reference/S3method.dpi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"[S3 methods] for DPI() and DPI_curve(). â€” S3method.dpi","text":"object Object (class dpi) returned DPI(). ... arguments (currently used). x Object (class dpi dpi.curve) returned DPI() DPI_curve(). digits Number decimal places. Defaults 3. file File name saved plot (\".png\" \".pdf\"). width, height Width height (inches) saved plot. Defaults 6 4. dpi Dots per inch (figure resolution). Defaults 500.","code":""},{"path":"https://psychbruce.github.io/DPI/reference/S3method.network.html","id":null,"dir":"Reference","previous_headings":"","what":"[S3 methods] for cor_net(), BNs_dag(), and DPI_dag(). â€” S3method.network","title":"[S3 methods] for cor_net(), BNs_dag(), and DPI_dag(). â€” S3method.network","text":"Transform qgraph ggplot plot(cor.net) plot(bns.dag) plot(dpi.dag) Plot network results print(cor.net) print(bns.dag) print(dpi.dag)","code":""},{"path":"https://psychbruce.github.io/DPI/reference/S3method.network.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"[S3 methods] for cor_net(), BNs_dag(), and DPI_dag(). â€” S3method.network","text":"","code":"# S3 method for class 'cor.net' plot(x, scale = 1.2, ...)  # S3 method for class 'cor.net' print(x, scale = 1.2, file = NULL, width = 6, height = 4, dpi = 500, ...)  # S3 method for class 'bns.dag' plot(x, algorithm, scale = 1.2, ...)  # S3 method for class 'bns.dag' print(   x,   algorithm = names(x),   scale = 1.2,   file = NULL,   width = 6,   height = 4,   dpi = 500,   ... )  # S3 method for class 'dpi.dag' plot(   x,   k = min(x$DPI$k.cov),   show.label = TRUE,   digits.dpi = 2,   faded.dpi = FALSE,   faded.dpi.limit = c(0, 0.25),   color.dpi.insig = \"#EEEEEEEE\",   scale = 1.2,   ... )  # S3 method for class 'dpi.dag' print(   x,   k = min(x$DPI$k.cov),   show.label = TRUE,   digits.dpi = 2,   faded.dpi = FALSE,   faded.dpi.limit = c(0, 0.25),   color.dpi.insig = \"#EEEEEEEE\",   scale = 1.2,   file = NULL,   width = 6,   height = 4,   dpi = 500,   ... )"},{"path":"https://psychbruce.github.io/DPI/reference/S3method.network.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"[S3 methods] for cor_net(), BNs_dag(), and DPI_dag(). â€” S3method.network","text":"x Object (class cor.net / bns.dag / dpi.dag) returned cor_net() / BNs_dag() / DPI_dag(). scale Scale grob object qgraph ggplot canvas. Defaults 1.2. ... arguments (currently used). file File name saved plot (\".png\" \".pdf\"). width, height Width height (inches) saved plot. Defaults 6 4. dpi Dots per inch (figure resolution). Defaults 500. algorithm [bns.dag] Algorithm(s) display. Defaults plot finally integrated DAG BN results algorithm x. k [dpi.dag] single value k.cov produce DPI(k) DAG. Defaults min(x$DPI$k.cov). show.label [dpi.dag] Show labels partial correlations, DPI(k), significance edges. Defaults TRUE. digits.dpi [dpi.dag] Number decimal places DPI values displayed DAG edges. Defaults 2. faded.dpi [dpi.dag] Transparency edges according value DPI. Defaults FALSE. faded.dpi.limit [dpi.dag] Lower upper limits abs(DPI) \"00\" \"FF\" transparency edges. Defaults c(0, 0.25). color.dpi.insig [dpi.dag] Edge color insignificant DPIs. Defaults \"#EEEEEEEE\" (faded light grey).","code":""},{"path":"https://psychbruce.github.io/DPI/reference/S3method.network.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"[S3 methods] for cor_net(), BNs_dag(), and DPI_dag(). â€” S3method.network","text":"Return ggplot object can modified used ggplot2::ggsave() cowplot::plot_grid().","code":""},{"path":"https://psychbruce.github.io/DPI/reference/cor_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Produce a symmetric correlation matrix from values. â€” cor_matrix","title":"Produce a symmetric correlation matrix from values. â€” cor_matrix","text":"Produce symmetric correlation matrix values.","code":""},{"path":"https://psychbruce.github.io/DPI/reference/cor_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produce a symmetric correlation matrix from values. â€” cor_matrix","text":"","code":"cor_matrix(...)"},{"path":"https://psychbruce.github.io/DPI/reference/cor_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produce a symmetric correlation matrix from values. â€” cor_matrix","text":"... Correlation values transform symmetric correlation matrix (row).","code":""},{"path":"https://psychbruce.github.io/DPI/reference/cor_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produce a symmetric correlation matrix from values. â€” cor_matrix","text":"Return symmetric correlation matrix.","code":""},{"path":"https://psychbruce.github.io/DPI/reference/cor_matrix.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Produce a symmetric correlation matrix from values. â€” cor_matrix","text":"","code":"cor_matrix(   1.0, 0.7, 0.3,   0.7, 1.0, 0.5,   0.3, 0.5, 1.0 ) #>      [,1] [,2] [,3] #> [1,]  1.0  0.7  0.3 #> [2,]  0.7  1.0  0.5 #> [3,]  0.3  0.5  1.0  cor_matrix(   1.0, NA, NA,   0.7, 1.0, NA,   0.3, 0.5, 1.0 ) #>      [,1] [,2] [,3] #> [1,]  1.0   NA   NA #> [2,]  0.7  1.0   NA #> [3,]  0.3  0.5    1"},{"path":"https://psychbruce.github.io/DPI/reference/cor_net.html","id":null,"dir":"Reference","previous_headings":"","what":"Correlation and partial correlation networks. â€” cor_net","title":"Correlation and partial correlation networks. â€” cor_net","text":"Correlation partial correlation networks (also called Gaussian graphical models, GGMs).","code":""},{"path":"https://psychbruce.github.io/DPI/reference/cor_net.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Correlation and partial correlation networks. â€” cor_net","text":"","code":"cor_net(   data,   index = c(\"cor\", \"pcor\"),   show.label = TRUE,   show.insig = FALSE,   show.cutoff = FALSE,   faded = FALSE,   node.text.size = 1.2,   node.group = NULL,   node.color = NULL,   edge.color.pos = \"#0571B0\",   edge.color.neg = \"#CA0020\",   edge.color.non = \"#EEEEEEEE\",   edge.width.min = \"sig\",   edge.width.max = NULL,   edge.label.mrg = 0.01,   file = NULL,   width = 6,   height = 4,   dpi = 500,   ... )"},{"path":"https://psychbruce.github.io/DPI/reference/cor_net.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Correlation and partial correlation networks. â€” cor_net","text":"data Data. index Type graph: \"cor\" (raw correlation network) \"pcor\" (partial correlation network). Defaults \"cor\". show.label Show labels correlation coefficients significance edges. Defaults TRUE. show.insig Show edges insignificant correlations (p > 0.05). Defaults FALSE. change significance level, please set alpha (defaults alpha=0.05). show.cutoff Show cut-values correlations. Defaults FALSE. faded Transparency edges according effect size correlation. Defaults FALSE. node.text.size Scalar font size node (variable) labels. Defaults 1.2. node.group list indicates nodes belong together, element list vector integers identifying column numbers variables belong together. node.color vector color element node.group, color node. edge.color.pos Color (significant) positive values. Defaults \"#0571B0\" (blue ColorBrewer's RdBu palette). edge.color.neg Color (significant) negative values. Defaults \"#CA0020\" (red ColorBrewer's RdBu palette). edge.color.non Color insignificant values. Defaults \"#EEEEEEEE\" (faded light grey). edge.width.min Minimum value edge strength scale edge widths. Defaults sig (threshold significant values). edge.width.max Maximum value edge strength scale edge widths. Defaults NULL (undirected correlation networks) 1.5 (directed acyclic networks better display arrows). edge.label.mrg Margin background box around edge label. Defaults 0.01. file File name saved plot (\".png\" \".pdf\"). width, height Width height (inches) saved plot. Defaults 6 4. dpi Dots per inch (figure resolution). Defaults 500. ... Arguments passed qgraph().","code":""},{"path":"https://psychbruce.github.io/DPI/reference/cor_net.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Correlation and partial correlation networks. â€” cor_net","text":"Return list (class cor.net) (partial) correlation results qgraph object.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/DPI/reference/cor_net.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Correlation and partial correlation networks. â€” cor_net","text":"","code":"# correlation network cor_net(airquality) #> Displaying Correlation Network  cor_net(airquality, show.insig=TRUE) #> Displaying Correlation Network   # partial correlation network cor_net(airquality, \"pcor\") #> Displaying Partial Correlation Network  cor_net(airquality, \"pcor\", show.insig=TRUE) #> Displaying Partial Correlation Network   # modify ggplot attributes p = cor_net(airquality, \"pcor\") gg = plot(p)  # return a ggplot object gg + labs(title=\"Partial Correlation Network\")"},{"path":"https://psychbruce.github.io/DPI/reference/p_to_bf.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert p values to approximate (pseudo) Bayes Factors (PseudoBF10). â€” p_to_bf","title":"Convert p values to approximate (pseudo) Bayes Factors (PseudoBF10). â€” p_to_bf","text":"Convert p values approximate (pseudo) Bayes Factors (PseudoBF10). transformation suggested Wagenmakers (2022).","code":""},{"path":"https://psychbruce.github.io/DPI/reference/p_to_bf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert p values to approximate (pseudo) Bayes Factors (PseudoBF10). â€” p_to_bf","text":"","code":"p_to_bf(p, n, log = FALSE, label = FALSE)"},{"path":"https://psychbruce.github.io/DPI/reference/p_to_bf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert p values to approximate (pseudo) Bayes Factors (PseudoBF10). â€” p_to_bf","text":"p p value(s). n Number observations. log Return log(BF10) raw BF10. Defaults FALSE. label Add labels (.e., names) returned values. Defaults FALSE.","code":""},{"path":"https://psychbruce.github.io/DPI/reference/p_to_bf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert p values to approximate (pseudo) Bayes Factors (PseudoBF10). â€” p_to_bf","text":"(named) numeric vector pseudo Bayes Factors (\\(\\text{PseudoBF}_{10}\\)).","code":""},{"path":"https://psychbruce.github.io/DPI/reference/p_to_bf.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Convert p values to approximate (pseudo) Bayes Factors (PseudoBF10). â€” p_to_bf","text":"Wagenmakers, E.-J. (2022). Approximate objective Bayes factors p-values sample size: \\(3p\\sqrt{n}\\) rule. PsyArXiv. doi:10.31234/osf.io/egydq","code":""},{"path":[]},{"path":"https://psychbruce.github.io/DPI/reference/p_to_bf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert p values to approximate (pseudo) Bayes Factors (PseudoBF10). â€” p_to_bf","text":"","code":"p_to_bf(0.05, 100) #> [1] 0.6666667 p_to_bf(c(0.01, 0.05), 100) #> [1] 3.3333333 0.6666667 p_to_bf(c(0.001, 0.01, 0.05, 0.1), 100, label=TRUE) #> (p = 0.001, n = 100)  (p = 0.01, n = 100)  (p = 0.05, n = 100)  #>           33.3333333            3.3333333            0.6666667  #>   (p = 0.1, n = 100)  #>            0.3333333  p_to_bf(c(0.001, 0.01, 0.05, 0.1), 1000, label=TRUE) #> (p = 0.001, n = 1000)  (p = 0.01, n = 1000)  (p = 0.05, n = 1000)  #>            10.5409255             1.0540926             0.2108185  #>   (p = 0.1, n = 1000)  #>             0.1054093"},{"path":"https://psychbruce.github.io/DPI/reference/sim_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate data from a multivariate normal distribution. â€” sim_data","title":"Simulate data from a multivariate normal distribution. â€” sim_data","text":"Simulate data multivariate normal distribution.","code":""},{"path":"https://psychbruce.github.io/DPI/reference/sim_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate data from a multivariate normal distribution. â€” sim_data","text":"","code":"sim_data(n, k, cor = NULL, exact = TRUE, seed = NULL)"},{"path":"https://psychbruce.github.io/DPI/reference/sim_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate data from a multivariate normal distribution. â€” sim_data","text":"n Number observations (cases). k Number variables. ignored cor specifies correlation matrix. cor correlation value correlation matrix variables. Defaults NULL generates completely random data regardless empirical correlations. exact Ensure sample correlation matrix exact specified cor. argument passed empirical mvrnorm(). Defaults TRUE. seed Random seed replicable results. Defaults NULL.","code":""},{"path":"https://psychbruce.github.io/DPI/reference/sim_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate data from a multivariate normal distribution. â€” sim_data","text":"Return data.frame simulated data.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/DPI/reference/sim_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate data from a multivariate normal distribution. â€” sim_data","text":"","code":"d1 = sim_data(n=100, k=5, seed=1) cor_net(d1) #> Displaying Correlation Network   d2 = sim_data(n=100, k=5, cor=0.2, seed=1) cor_net(d2) #> Displaying Correlation Network   cor.mat = cor_matrix(   1.0, 0.7, 0.3,   0.7, 1.0, 0.5,   0.3, 0.5, 1.0 ) d3 = sim_data(n=100, cor=cor.mat, seed=1) cor_net(d3) #> Displaying Correlation Network"},{"path":"https://psychbruce.github.io/DPI/reference/sim_data_exp.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate experiment-like data with independent binary Xs. â€” sim_data_exp","title":"Simulate experiment-like data with independent binary Xs. â€” sim_data_exp","text":"Simulate experiment-like data independent binary Xs.","code":""},{"path":"https://psychbruce.github.io/DPI/reference/sim_data_exp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate experiment-like data with independent binary Xs. â€” sim_data_exp","text":"","code":"sim_data_exp(   n,   r.xy,   approx = TRUE,   tol = 0.01,   max.iter = 30,   verbose = FALSE,   seed = NULL )"},{"path":"https://psychbruce.github.io/DPI/reference/sim_data_exp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate experiment-like data with independent binary Xs. â€” sim_data_exp","text":"n Number observations (cases). r.xy vector expected correlations X (binary independent variable: 0 1) Y. approx Make sample correlation matrix approximate values specified r.xy, using method orthogonal decomposition residuals (.e., making residuals independent Xs). Defaults TRUE. tol Tolerance absolute difference specified empirical correlations. Defaults 0.01. max.iter Maximum iterations approximation. iterations produce approximate correlations, absolute differences convergent 30 iterations. Defaults 30. verbose Print information iterations satisfy tolerance. Defaults FALSE. seed Random seed replicable results. Defaults NULL.","code":""},{"path":"https://psychbruce.github.io/DPI/reference/sim_data_exp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate experiment-like data with independent binary Xs. â€” sim_data_exp","text":"Return data.frame simulated data.","code":""},{"path":[]},{"path":"https://psychbruce.github.io/DPI/reference/sim_data_exp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate experiment-like data with independent binary Xs. â€” sim_data_exp","text":"","code":"data = sim_data_exp(n=1000, r.xy=c(0.5, 0.3), seed=1) cor(data)  # tol = 0.01 #>             X1          X2         Y #> X1 1.000000000 0.004486829 0.5053679 #> X2 0.004486829 1.000000000 0.3073449 #> Y  0.505367897 0.307344860 1.0000000  data = sim_data_exp(n=1000, r.xy=c(0.5, 0.3), seed=1,                     verbose=TRUE) #> 1 iterations done: abs(cor.diff.) = 0.01087 and 0.01431 #> 2 iterations done: abs(cor.diff.) = 0.00754 and 0.0101 #> 3 iterations satisfied tolerance of 0.01 cor(data)  # print iteration information #>             X1          X2         Y #> X1 1.000000000 0.004486829 0.5053679 #> X2 0.004486829 1.000000000 0.3073449 #> Y  0.505367897 0.307344860 1.0000000  data = sim_data_exp(n=1000, r.xy=c(0.5, 0.3), seed=1,                     verbose=TRUE, tol=0.001) #> 1 iterations done: abs(cor.diff.) = 0.010872 and 0.014311 #> 2 iterations done: abs(cor.diff.) = 0.007539 and 0.010095 #> 3 iterations done: abs(cor.diff.) = 0.005368 and 0.007345 #> 4 iterations done: abs(cor.diff.) = 0.003956 and 0.005555 #> 5 iterations done: abs(cor.diff.) = 0.003039 and 0.004392 #> 6 iterations done: abs(cor.diff.) = 0.002444 and 0.003637 #> 7 iterations done: abs(cor.diff.) = 0.002058 and 0.003147 #> 8 iterations done: abs(cor.diff.) = 0.001807 and 0.002829 #> 9 iterations done: abs(cor.diff.) = 0.001645 and 0.002623 #> 10 iterations done: abs(cor.diff.) = 0.00154 and 0.002489 #> 11 iterations done: abs(cor.diff.) = 0.001472 and 0.002403 #> 12 iterations done: abs(cor.diff.) = 0.001427 and 0.002347 #> 13 iterations done: abs(cor.diff.) = 0.001399 and 0.00231 #> 14 iterations done: abs(cor.diff.) = 0.00138 and 0.002287 #> 15 iterations done: abs(cor.diff.) = 0.001368 and 0.002272 #> 16 iterations done: abs(cor.diff.) = 0.00136 and 0.002262 #> 17 iterations done: abs(cor.diff.) = 0.001355 and 0.002255 #> 18 iterations done: abs(cor.diff.) = 0.001352 and 0.002251 #> 19 iterations done: abs(cor.diff.) = 0.00135 and 0.002248 #> 20 iterations done: abs(cor.diff.) = 0.001349 and 0.002247 #> 21 iterations done: abs(cor.diff.) = 0.001348 and 0.002245 #> 22 iterations done: abs(cor.diff.) = 0.001347 and 0.002245 #> 23 iterations done: abs(cor.diff.) = 0.001347 and 0.002244 #> 24 iterations done: abs(cor.diff.) = 0.001346 and 0.002244 #> 25 iterations done: abs(cor.diff.) = 0.001346 and 0.002244 #> 26 iterations done: abs(cor.diff.) = 0.001346 and 0.002244 #> 27 iterations done: abs(cor.diff.) = 0.001346 and 0.002244 #> 28 iterations done: abs(cor.diff.) = 0.001346 and 0.002244 #> 29 iterations done: abs(cor.diff.) = 0.001346 and 0.002243 #> 30 iterations done: abs(cor.diff.) = 0.001346 and 0.002243 cor(data)  # more approximate, though not exact #>             X1          X2         Y #> X1 1.000000000 0.004486829 0.5013461 #> X2 0.004486829 1.000000000 0.3022435 #> Y  0.501346082 0.302243457 1.0000000  data = sim_data_exp(n=1000, r.xy=c(0.5, 0.3), seed=1,                     approx=FALSE) cor(data)  # far less exact #>             X1          X2         Y #> X1 1.000000000 0.004486829 0.4793269 #> X2 0.004486829 1.000000000 0.3322344 #> Y  0.479326865 0.332234387 1.0000000"},{"path":"https://psychbruce.github.io/DPI/news/index.html","id":"dpi-20262","dir":"Changelog","previous_headings":"","what":"DPI 2026.2","title":"DPI 2026.2","text":"Minor changes improvements.","code":""},{"path":"https://psychbruce.github.io/DPI/news/index.html","id":"dpi-202511","dir":"Changelog","previous_headings":"","what":"DPI 2025.11","title":"DPI 2025.11","text":"CRAN release: 2025-11-24 Improved DPI_dag() plot.dpi.dag(). Also forced plot strictly show DAG changing edge color insignificant DPI faded grey. (Fixed patch version 2025.10-1) Fixed DPI_curve() wrong (reverse) direction DPI caused change parameter order x y version 2025.10. (Fixed patch version 2025.10-1) Fixed bug caused dpi parameter-object name conflict (internally) saving DPI() results file.","code":""},{"path":"https://psychbruce.github.io/DPI/news/index.html","id":"dpi-202510","dir":"Changelog","previous_headings":"","what":"DPI 2025.10","title":"DPI 2025.10","text":"CRAN release: 2025-10-16 version contains breaking changes function names visualization methods. Added DPI_dag(): Directed acyclic graphs (DAGs) via DPI exploratory analysis (causal discovery) significant partial correlations. bonf: Bonferroni correction control false positive rates among multiple pairwise DPI tests. pseudoBF: Use normalized pseudo Bayes Factors sigmoid(log(PseudoBF10)) Significance score (0~1). Pseudo Bayes Factors computed using transformation rules proposed Wagenmakers (2022) https://doi.org/10.31234/osf.io/egydq. Added S3 methods plot.cor.net(), plot.bns.dag(), plot.dpi.dag() can transform qgraph base-plot objects ggplot objects stable flexible visualization. Added p_to_bf(): Convert p values pseudo Bayes Factors (PseudoBF10\\text{PseudoBF}_{10}). Renamed cor_network() cor_net(), dag_network() BNs_dag(), matrix_cor() cor_matrix(). Fixed cor_net() return exactly correct p values (partial) correlation coefficients. Improved output information console plot.","code":""},{"path":"https://psychbruce.github.io/DPI/news/index.html","id":"dpi-20259","dir":"Changelog","previous_headings":"","what":"DPI 2025.9","title":"DPI 2025.9","text":"CRAN release: 2025-09-20 version contains breaking changes algorithm functionality. earlier version algorithm, strength score computed tÎ²XY|Covs2=tr.partialXY|Covs2âˆˆ[0,+âˆž)t_{\\beta_{XY|Covs}}^2 = t_{r.partial_{XY|Covs}}^2 \\[0, +\\infty). algorithm performs well new Sigmoid(pÎ±)\\text{Sigmoid}(\\frac{p}{\\alpha}) approach (e.g., low false positive false negative rates), t2t^2 major flaw values converge limited range final DPI values heavily determined t2t^2, desired attribute. contrast, new algorithm can make significance score likely â€œ-switchâ€, values likely approximating 0 1, thereby minimizing impact interpretation final DPI values. Renamed data_random() sim_data() enhanced functionality supports data simulation multivariate normal distribution, using MASS::mvrnorm(). Added sim_data_exp(): Simulate experiment-like data independent binary Xs. Used gc() DPI(), DPI_curve(), dag_network() memory garbage collection. Provided better example dag_network() arranging multiple base-R-style plots using aplot::plot_list().","code":""},{"path":"https://psychbruce.github.io/DPI/news/index.html","id":"dpi-20258","dir":"Changelog","previous_headings":"","what":"DPI 2025.8","title":"DPI 2025.8","text":"CRAN release: 2025-08-20 Added dag_network(): Directed acyclic graphs (DAGs) via causal Bayesian networks (BNs). Improved cor_network(): Correlation partial correlation networks. Moved help pages S3 method functions S3method.dpi S3method.network made internal topics.","code":""},{"path":"https://psychbruce.github.io/DPI/news/index.html","id":"dpi-20256","dir":"Changelog","previous_headings":"","what":"DPI 2025.6","title":"DPI 2025.6","text":"CRAN release: 2025-06-18 CRAN package publication. Initial public release GitHub. Developed core functions package logo.","code":""}]
